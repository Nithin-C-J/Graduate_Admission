{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Kaggle dataset for graduate admission.The predicated output for this dataset gives us a fair idea about students chances for getting admission in particular University."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Admission_Predict.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200.500000</td>\n",
       "      <td>316.807500</td>\n",
       "      <td>107.410000</td>\n",
       "      <td>3.087500</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.452500</td>\n",
       "      <td>8.598925</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.724350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.614301</td>\n",
       "      <td>11.473646</td>\n",
       "      <td>6.069514</td>\n",
       "      <td>1.143728</td>\n",
       "      <td>1.006869</td>\n",
       "      <td>0.898478</td>\n",
       "      <td>0.596317</td>\n",
       "      <td>0.498362</td>\n",
       "      <td>0.142609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.750000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>200.500000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.610000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>300.250000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.062500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
       "count  400.000000  400.000000   400.000000         400.000000  400.000000   \n",
       "mean   200.500000  316.807500   107.410000           3.087500    3.400000   \n",
       "std    115.614301   11.473646     6.069514           1.143728    1.006869   \n",
       "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
       "25%    100.750000  308.000000   103.000000           2.000000    2.500000   \n",
       "50%    200.500000  317.000000   107.000000           3.000000    3.500000   \n",
       "75%    300.250000  325.000000   112.000000           4.000000    4.000000   \n",
       "max    400.000000  340.000000   120.000000           5.000000    5.000000   \n",
       "\n",
       "             LOR         CGPA    Research  Chance of Admit   \n",
       "count  400.000000  400.000000  400.000000        400.000000  \n",
       "mean     3.452500    8.598925    0.547500          0.724350  \n",
       "std      0.898478    0.596317    0.498362          0.142609  \n",
       "min      1.000000    6.800000    0.000000          0.340000  \n",
       "25%      3.000000    8.170000    0.000000          0.640000  \n",
       "50%      3.500000    8.610000    1.000000          0.730000  \n",
       "75%      4.000000    9.062500    1.000000          0.830000  \n",
       "max      5.000000    9.920000    1.000000          0.970000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      "Serial No.           400 non-null int64\n",
      "GRE Score            400 non-null int64\n",
      "TOEFL Score          400 non-null int64\n",
      "University Rating    400 non-null int64\n",
      "SOP                  400 non-null float64\n",
      "LOR                  400 non-null float64\n",
      "CGPA                 400 non-null float64\n",
      "Research             400 non-null int64\n",
      "Chance of Admit      400 non-null float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.2 KB\n"
     ]
    }
   ],
   "source": [
    "#information about our dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col0 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col1 {\n",
       "            background-color:  #edd1c2;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col2 {\n",
       "            background-color:  #c9d7f0;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col4 {\n",
       "            background-color:  #d5dbe5;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col5 {\n",
       "            background-color:  #8db0fe;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col6 {\n",
       "            background-color:  #efcebd;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col7 {\n",
       "            background-color:  #7ea1fa;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col8 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col0 {\n",
       "            background-color:  #f4c5ad;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col1 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col2 {\n",
       "            background-color:  #f6a385;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col3 {\n",
       "            background-color:  #d9dce1;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col4 {\n",
       "            background-color:  #f6bea4;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col5 {\n",
       "            background-color:  #8fb1fe;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col6 {\n",
       "            background-color:  #7da0f9;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col7 {\n",
       "            background-color:  #7a9df8;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col8 {\n",
       "            background-color:  #c6d6f1;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col0 {\n",
       "            background-color:  #ccd9ed;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col1 {\n",
       "            background-color:  #f7af91;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col2 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col3 {\n",
       "            background-color:  #d7dce3;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col4 {\n",
       "            background-color:  #abc8fd;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col5 {\n",
       "            background-color:  #94b6ff;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col6 {\n",
       "            background-color:  #779af7;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col7 {\n",
       "            background-color:  #5a78e4;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col8 {\n",
       "            background-color:  #a9c6fd;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col1 {\n",
       "            background-color:  #c4d5f3;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col2 {\n",
       "            background-color:  #d4dbe6;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col3 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col4 {\n",
       "            background-color:  #93b5fe;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col5 {\n",
       "            background-color:  #f39475;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col6 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col7 {\n",
       "            background-color:  #f3c7b1;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col8 {\n",
       "            background-color:  #a7c5fe;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col0 {\n",
       "            background-color:  #c7d7f0;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col1 {\n",
       "            background-color:  #ebd3c6;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col2 {\n",
       "            background-color:  #92b4fe;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col3 {\n",
       "            background-color:  #7b9ff9;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col4 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col6 {\n",
       "            background-color:  #7295f4;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col7 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col8 {\n",
       "            background-color:  #ecd3c5;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col0 {\n",
       "            background-color:  #82a6fb;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col1 {\n",
       "            background-color:  #5e7de7;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col2 {\n",
       "            background-color:  #84a7fc;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col3 {\n",
       "            background-color:  #f4987a;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col4 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col5 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col6 {\n",
       "            background-color:  #779af7;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col7 {\n",
       "            background-color:  #df634e;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col8 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col0 {\n",
       "            background-color:  #f6bea4;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col1 {\n",
       "            background-color:  #88abfd;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col2 {\n",
       "            background-color:  #9fbfff;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col3 {\n",
       "            background-color:  #6c8ff1;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col4 {\n",
       "            background-color:  #b3cdfb;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col5 {\n",
       "            background-color:  #aec9fc;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col6 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col7 {\n",
       "            background-color:  #8fb1fe;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col8 {\n",
       "            background-color:  #b9d0f9;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col0 {\n",
       "            background-color:  #6687ed;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col2 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col3 {\n",
       "            background-color:  #efcfbf;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col5 {\n",
       "            background-color:  #e16751;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col6 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col7 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col8 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col0 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col1 {\n",
       "            background-color:  #b7cff9;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col2 {\n",
       "            background-color:  #b1cbfc;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col3 {\n",
       "            background-color:  #b5cdfa;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col4 {\n",
       "            background-color:  #f4c6af;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col5 {\n",
       "            background-color:  #6687ed;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col6 {\n",
       "            background-color:  #9ebeff;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col7 {\n",
       "            background-color:  #6b8df0;\n",
       "            color:  #000000;\n",
       "        }    #T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col8 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5ab\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>        <th class=\"col_heading level0 col2\" >2</th>        <th class=\"col_heading level0 col3\" >3</th>        <th class=\"col_heading level0 col4\" >4</th>        <th class=\"col_heading level0 col5\" >5</th>        <th class=\"col_heading level0 col6\" >6</th>        <th class=\"col_heading level0 col7\" >7</th>        <th class=\"col_heading level0 col8\" >8</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5ablevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col1\" class=\"data row0 col1\" >0.45957</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col2\" class=\"data row0 col2\" >0.195566</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col3\" class=\"data row0 col3\" >-0.438985</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col4\" class=\"data row0 col4\" >0.168087</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col5\" class=\"data row0 col5\" >-0.121684</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col6\" class=\"data row0 col6\" >0.494017</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col7\" class=\"data row0 col7\" >-0.238448</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow0_col8\" class=\"data row0 col8\" >-0.361886</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5ablevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col0\" class=\"data row1 col0\" >0.45957</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col1\" class=\"data row1 col1\" >1</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col2\" class=\"data row1 col2\" >0.611315</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col3\" class=\"data row1 col3\" >0.259963</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col4\" class=\"data row1 col4\" >0.447112</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col5\" class=\"data row1 col5\" >-0.11356</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col6\" class=\"data row1 col6\" >0.0362479</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col7\" class=\"data row1 col7\" >-0.259896</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow1_col8\" class=\"data row1 col8\" >0.209784</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5ablevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col0\" class=\"data row2 col0\" >0.195566</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col1\" class=\"data row2 col1\" >0.611315</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col2\" class=\"data row2 col2\" >1</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col3\" class=\"data row2 col3\" >0.251037</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col4\" class=\"data row2 col4\" >-0.0373521</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col5\" class=\"data row2 col5\" >-0.092394</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col6\" class=\"data row2 col6\" >0.0170831</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col7\" class=\"data row2 col7\" >-0.407235</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow2_col8\" class=\"data row2 col8\" >0.0879038</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5ablevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col0\" class=\"data row3 col0\" >-0.438985</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col1\" class=\"data row3 col1\" >0.259963</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col2\" class=\"data row3 col2\" >0.251037</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col3\" class=\"data row3 col3\" >1</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col4\" class=\"data row3 col4\" >-0.14748</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col5\" class=\"data row3 col5\" >0.645247</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col6\" class=\"data row3 col6\" >-0.211751</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col7\" class=\"data row3 col7\" >0.397388</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow3_col8\" class=\"data row3 col8\" >0.084496</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5ablevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col0\" class=\"data row4 col0\" >0.168087</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col1\" class=\"data row4 col1\" >0.447112</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col2\" class=\"data row4 col2\" >-0.0373521</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col3\" class=\"data row4 col3\" >-0.14748</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col4\" class=\"data row4 col4\" >1</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col5\" class=\"data row4 col5\" >-0.500359</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col6\" class=\"data row4 col6\" >0.000303618</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col7\" class=\"data row4 col7\" >-0.568069</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow4_col8\" class=\"data row4 col8\" >0.405314</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5ablevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col0\" class=\"data row5 col0\" >-0.121684</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col1\" class=\"data row5 col1\" >-0.11356</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col2\" class=\"data row5 col2\" >-0.092394</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col3\" class=\"data row5 col3\" >0.645247</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col4\" class=\"data row5 col4\" >-0.500359</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col5\" class=\"data row5 col5\" >1</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col6\" class=\"data row5 col6\" >0.0189393</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col7\" class=\"data row5 col7\" >0.792286</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow5_col8\" class=\"data row5 col8\" >-0.291083</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5ablevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col0\" class=\"data row6 col0\" >0.494017</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col1\" class=\"data row6 col1\" >0.0362479</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col2\" class=\"data row6 col2\" >0.0170831</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col3\" class=\"data row6 col3\" >-0.211751</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col4\" class=\"data row6 col4\" >0.000303618</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col5\" class=\"data row6 col5\" >0.0189393</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col6\" class=\"data row6 col6\" >1</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col7\" class=\"data row6 col7\" >-0.166828</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow6_col8\" class=\"data row6 col8\" >0.149443</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5ablevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col0\" class=\"data row7 col0\" >-0.238448</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col1\" class=\"data row7 col1\" >-0.259896</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col2\" class=\"data row7 col2\" >-0.407235</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col3\" class=\"data row7 col3\" >0.397388</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col4\" class=\"data row7 col4\" >-0.568069</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col5\" class=\"data row7 col5\" >0.792286</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col6\" class=\"data row7 col6\" >-0.166828</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col7\" class=\"data row7 col7\" >1</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow7_col8\" class=\"data row7 col8\" >-0.325124</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5ablevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col0\" class=\"data row8 col0\" >-0.361886</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col1\" class=\"data row8 col1\" >0.209784</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col2\" class=\"data row8 col2\" >0.0879038</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col3\" class=\"data row8 col3\" >0.084496</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col4\" class=\"data row8 col4\" >0.405314</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col5\" class=\"data row8 col5\" >-0.291083</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col6\" class=\"data row8 col6\" >0.149443</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col7\" class=\"data row8 col7\" >-0.325124</td>\n",
       "                        <td id=\"T_c3fae19a_4714_11ea_a511_f01898ecc5abrow8_col8\" class=\"data row8 col8\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9c7117ec50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rs = np.random.RandomState(0)\n",
    "df = pd.DataFrame(rs.rand(9,9))\n",
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Serial No.</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.097526</td>\n",
       "      <td>-0.147932</td>\n",
       "      <td>-0.169948</td>\n",
       "      <td>-0.166932</td>\n",
       "      <td>-0.088221</td>\n",
       "      <td>-0.045608</td>\n",
       "      <td>-0.063138</td>\n",
       "      <td>0.042336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRE Score</th>\n",
       "      <td>-0.097526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835977</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.612831</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.833060</td>\n",
       "      <td>0.580391</td>\n",
       "      <td>0.802610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL Score</th>\n",
       "      <td>-0.147932</td>\n",
       "      <td>0.835977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695590</td>\n",
       "      <td>0.657981</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.828417</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>0.791594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <td>-0.169948</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.695590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>0.660123</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.447783</td>\n",
       "      <td>0.711250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>-0.166932</td>\n",
       "      <td>0.612831</td>\n",
       "      <td>0.657981</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.729593</td>\n",
       "      <td>0.718144</td>\n",
       "      <td>0.444029</td>\n",
       "      <td>0.675732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>-0.088221</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.660123</td>\n",
       "      <td>0.729593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670211</td>\n",
       "      <td>0.396859</td>\n",
       "      <td>0.669889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>-0.045608</td>\n",
       "      <td>0.833060</td>\n",
       "      <td>0.828417</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.718144</td>\n",
       "      <td>0.670211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521654</td>\n",
       "      <td>0.873289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>-0.063138</td>\n",
       "      <td>0.580391</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>0.447783</td>\n",
       "      <td>0.444029</td>\n",
       "      <td>0.396859</td>\n",
       "      <td>0.521654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance of Admit</th>\n",
       "      <td>0.042336</td>\n",
       "      <td>0.802610</td>\n",
       "      <td>0.791594</td>\n",
       "      <td>0.711250</td>\n",
       "      <td>0.675732</td>\n",
       "      <td>0.669889</td>\n",
       "      <td>0.873289</td>\n",
       "      <td>0.553202</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Serial No.  GRE Score  TOEFL Score  University Rating  \\\n",
       "Serial No.           1.000000  -0.097526    -0.147932          -0.169948   \n",
       "GRE Score           -0.097526   1.000000     0.835977           0.668976   \n",
       "TOEFL Score         -0.147932   0.835977     1.000000           0.695590   \n",
       "University Rating   -0.169948   0.668976     0.695590           1.000000   \n",
       "SOP                 -0.166932   0.612831     0.657981           0.734523   \n",
       "LOR                 -0.088221   0.557555     0.567721           0.660123   \n",
       "CGPA                -0.045608   0.833060     0.828417           0.746479   \n",
       "Research            -0.063138   0.580391     0.489858           0.447783   \n",
       "Chance of Admit      0.042336   0.802610     0.791594           0.711250   \n",
       "\n",
       "                        SOP      LOR       CGPA  Research  Chance of Admit   \n",
       "Serial No.        -0.166932 -0.088221 -0.045608 -0.063138          0.042336  \n",
       "GRE Score          0.612831  0.557555  0.833060  0.580391          0.802610  \n",
       "TOEFL Score        0.657981  0.567721  0.828417  0.489858          0.791594  \n",
       "University Rating  0.734523  0.660123  0.746479  0.447783          0.711250  \n",
       "SOP                1.000000  0.729593  0.718144  0.444029          0.675732  \n",
       "LOR                0.729593  1.000000  0.670211  0.396859          0.669889  \n",
       "CGPA               0.718144  0.670211  1.000000  0.521654          0.873289  \n",
       "Research           0.444029  0.396859  0.521654  1.000000          0.553202  \n",
       "Chance of Admit    0.675732  0.669889  0.873289  0.553202          1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correlation matrix\n",
    "cor  = data.corr()\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
       "       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRE Score            0.802610\n",
       "TOEFL Score          0.791594\n",
       "University Rating    0.711250\n",
       "SOP                  0.675732\n",
       "LOR                  0.669889\n",
       "CGPA                 0.873289\n",
       "Chance of Admit      1.000000\n",
       "Name: Chance of Admit , dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List the variables with highest correlation with output variable\n",
    "#Correlation with output variable\n",
    "cor_target = abs(cor[\"Chance of Admit \"])\n",
    "\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.6]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So correlation matrix gives us some idea of how all the variables in our dataset are correlated to our output variable chance of admit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the research i did i have categrised the GRE Score into 4 categories.\n",
    "1.Excellent(score>=335)\n",
    "2.Better(score>=321.5)\n",
    "3.Good(score>=309)\n",
    "4.Below average(score<=307.5)\n",
    "\n",
    "Note : GRE is exam is conducted for total of 340 marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of people who fall in excellent category\n",
    "excellent = data[data['GRE Score'] >= 335]\n",
    "excellent['GRE Score'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of people who fall in Better score category\n",
    "Better = data[(data['GRE Score'] >= 321.5) & (data['GRE Score'] <= 334)]\n",
    "Better['GRE Score'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of people who fall in Good Score category\n",
    "Good = data[(data['GRE Score'] >= 309) & (data['GRE Score'] <= 320)]\n",
    "Good['GRE Score'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of people who fall in Below Average category\n",
    "Below_Average = data[data['GRE Score'] <= 307.5]\n",
    "Below_Average['GRE Score'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of people who have done research and not done research\n",
    "# 1=done research\n",
    "# 0=not done research\n",
    "data['Research'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph we can see that number of students who have done rsearch are more in our dataset compared to those who havent done research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of people having more than 80% chance of getting admission are\n",
    "Good_chance = data[data['Chance of Admit '] >= 0.8]\n",
    "Good_chance['Chance of Admit '].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dividing students in dataset based on university rating and \n",
    "# plotting the bar graph to count the number of students falling in different categories of universities.\n",
    "data['University Rating'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, it can be seen that maximum number of the students in our dataset are from the universisties having rating 3. ie, average college. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9c6047e4e0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot to check where our data is more concentrated based on TOEFL score\n",
    "plt.scatter(data['TOEFL Score'],data['Serial No.'],color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph we can say that most of the students in our dataset have TOEFL score in the range 105 to 115."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0        337          118                  4  4.5   4.5  9.65         1\n",
       "1        324          107                  4  4.0   4.5  8.87         1\n",
       "2        316          104                  3  3.0   3.5  8.00         1\n",
       "3        322          110                  3  3.5   2.5  8.67         1\n",
       "4        314          103                  2  2.0   3.0  8.21         0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We shouldn't include serial no. column in our x variable\n",
    "data.iloc[:,1:-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "395    0.82\n",
       "396    0.84\n",
       "397    0.91\n",
       "398    0.67\n",
       "399    0.95\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set chance of admit as your target or y variable\n",
    "data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the values for x and y variables\n",
    "# ie, our labels and target value\n",
    "x = data.iloc[:,1:-1].values\n",
    "y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Hold Out method for cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 7)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "300 rows out of 4oo rows are selected for training and 7 columns are selected as our labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "300 rows out of 400 rows are selected for training and 1 column is selected as our target concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the simple linear regression model on our training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7248631204868363"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,1:-1].values\n",
    "y = data.iloc[:,-1].values\n",
    "y=y>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use one hot encode to encode y variable to numeric values\n",
    "# Assigning numerical values and storing in another column\n",
    "y = labelencoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74, 0.56, 0.78, 0.52, 0.8 , 0.75, 0.96, 0.62, 0.79, 0.68, 0.48,\n",
       "       0.74, 0.76, 0.7 , 0.86, 0.91, 0.9 , 0.78, 0.7 , 0.59, 0.34, 0.71,\n",
       "       0.91, 0.69, 0.47, 0.92, 0.94, 0.71, 0.74, 0.64, 0.93, 0.77, 0.61,\n",
       "       0.6 , 0.84, 0.64, 0.84, 0.77, 0.63, 0.65, 0.81, 0.84, 0.65, 0.59,\n",
       "       0.7 , 0.57, 0.7 , 0.81, 0.88, 0.56, 0.8 , 0.94, 0.79, 0.62, 0.93,\n",
       "       0.76, 0.78, 0.85, 0.7 , 0.71, 0.8 , 0.79, 0.9 , 0.56, 0.67, 0.94,\n",
       "       0.74, 0.86, 0.76, 0.47, 0.64, 0.81, 0.73, 0.71, 0.73, 0.89, 0.93,\n",
       "       0.86, 0.75, 0.84, 0.67, 0.84, 0.71, 0.73, 0.76, 0.79, 0.54, 0.71,\n",
       "       0.85, 0.54, 0.56, 0.8 , 0.64, 0.44, 0.72, 0.85, 0.7 , 0.95, 0.34,\n",
       "       0.75, 0.8 , 0.85, 0.74, 0.58, 0.66, 0.8 , 0.59, 0.88, 0.69, 0.84,\n",
       "       0.57, 0.97, 0.75, 0.91, 0.65, 0.92, 0.44, 0.69, 0.65, 0.76, 0.62,\n",
       "       0.58, 0.46, 0.63, 0.94, 0.46, 0.77, 0.89, 0.96, 0.62, 0.57, 0.96,\n",
       "       0.96, 0.49, 0.71, 0.57, 0.74, 0.53, 0.92, 0.88, 0.91, 0.47, 0.85,\n",
       "       0.93, 0.64, 0.38, 0.61, 0.79, 0.65, 0.86, 0.66, 0.77, 0.72, 0.68,\n",
       "       0.69, 0.57, 0.65, 0.78, 0.86, 0.8 , 0.8 , 0.69, 0.62, 0.63, 0.79,\n",
       "       0.8 , 0.89, 0.64, 0.64, 0.72, 0.66, 0.71, 0.47, 0.68, 0.79, 0.5 ,\n",
       "       0.77, 0.84, 0.9 , 0.72, 0.72, 0.64, 0.82, 0.36, 0.49, 0.72, 0.76,\n",
       "       0.68, 0.58, 0.54, 0.73, 0.61, 0.76, 0.54, 0.65, 0.96, 0.93, 0.95,\n",
       "       0.87, 0.92, 0.72, 0.81, 0.9 , 0.53, 0.72, 0.76, 0.36, 0.67, 0.42,\n",
       "       0.73, 0.65, 0.78, 0.74, 0.82, 0.66, 0.67, 0.64, 0.96, 0.97, 0.71,\n",
       "       0.77, 0.68, 0.67, 0.7 , 0.67, 0.97, 0.94, 0.94, 0.49, 0.74, 0.38,\n",
       "       0.92, 0.73, 0.71, 0.56, 0.46, 0.73, 0.78, 0.73, 0.53, 0.69, 0.51,\n",
       "       0.52, 0.63, 0.52, 0.72, 0.42, 0.84, 0.58, 0.46, 0.75, 0.68, 0.94,\n",
       "       0.63, 0.97, 0.74, 0.91, 0.78, 0.89, 0.95, 0.82, 0.91, 0.83, 0.93,\n",
       "       0.72, 0.82, 0.79, 0.81, 0.83, 0.73, 0.76, 0.66, 0.71, 0.93, 0.71,\n",
       "       0.94, 0.78, 0.94, 0.96, 0.87, 0.46, 0.48, 0.94, 0.66, 0.64, 0.94,\n",
       "       0.66, 0.56, 0.7 , 0.7 , 0.82, 0.45, 0.81, 0.78, 0.7 , 0.62, 0.86,\n",
       "       0.45, 0.89, 0.86])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train>0.5\n",
    "y_train = labelencoder.fit_transform(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[320.  , 104.  ,   3.  , ...,   2.5 ,   8.57,   1.  ],\n",
       "       [315.  , 107.  ,   2.  , ...,   3.  ,   8.5 ,   1.  ],\n",
       "       [311.  , 107.  ,   4.  , ...,   4.5 ,   9.  ,   1.  ],\n",
       "       ...,\n",
       "       [290.  , 104.  ,   4.  , ...,   2.5 ,   7.46,   0.  ],\n",
       "       [339.  , 119.  ,   5.  , ...,   4.  ,   9.7 ,   0.  ],\n",
       "       [322.  , 110.  ,   4.  , ...,   5.  ,   9.13,   1.  ]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(criterion = 'entropy', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure to use modified y and not y_train\n",
    "dt_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[309.  , 105.  ,   5.  ,   3.5 ,   3.5 ,   8.56,   0.  ],\n",
       "       [308.  , 110.  ,   4.  ,   3.5 ,   3.  ,   8.6 ,   0.  ],\n",
       "       [326.  , 110.  ,   3.  ,   3.5 ,   3.5 ,   8.76,   1.  ],\n",
       "       [306.  , 105.  ,   2.  ,   3.  ,   2.5 ,   8.26,   0.  ],\n",
       "       [316.  , 105.  ,   3.  ,   3.  ,   3.5 ,   8.73,   0.  ],\n",
       "       [309.  , 100.  ,   2.  ,   3.  ,   3.  ,   8.1 ,   0.  ],\n",
       "       [312.  , 109.  ,   3.  ,   3.  ,   3.  ,   8.69,   0.  ],\n",
       "       [312.  , 104.  ,   3.  ,   3.5 ,   4.  ,   8.09,   0.  ],\n",
       "       [332.  , 118.  ,   2.  ,   4.5 ,   3.5 ,   9.36,   1.  ],\n",
       "       [331.  , 117.  ,   4.  ,   4.5 ,   5.  ,   9.42,   1.  ],\n",
       "       [300.  , 105.  ,   1.  ,   1.  ,   2.  ,   7.8 ,   0.  ],\n",
       "       [333.  , 113.  ,   5.  ,   4.  ,   4.  ,   9.28,   1.  ],\n",
       "       [320.  , 110.  ,   2.  ,   4.  ,   3.5 ,   8.56,   0.  ],\n",
       "       [302.  ,  99.  ,   1.  ,   2.  ,   2.  ,   7.25,   0.  ],\n",
       "       [328.  , 112.  ,   4.  ,   4.  ,   4.5 ,   9.1 ,   1.  ],\n",
       "       [311.  , 104.  ,   2.  ,   2.  ,   2.  ,   8.3 ,   0.  ],\n",
       "       [312.  ,  98.  ,   1.  ,   3.5 ,   3.  ,   8.18,   1.  ],\n",
       "       [329.  , 110.  ,   2.  ,   4.  ,   3.  ,   9.15,   1.  ],\n",
       "       [315.  ,  99.  ,   2.  ,   3.5 ,   3.  ,   7.89,   0.  ],\n",
       "       [313.  , 107.  ,   3.  ,   4.  ,   4.5 ,   8.69,   0.  ],\n",
       "       [329.  , 119.  ,   4.  ,   4.5 ,   4.5 ,   9.16,   1.  ],\n",
       "       [327.  , 113.  ,   4.  ,   4.5 ,   5.  ,   9.14,   0.  ],\n",
       "       [301.  , 106.  ,   4.  ,   2.5 ,   3.  ,   8.47,   0.  ],\n",
       "       [295.  ,  96.  ,   2.  ,   1.5 ,   2.  ,   7.34,   0.  ],\n",
       "       [320.  , 111.  ,   4.  ,   4.5 ,   3.5 ,   8.87,   1.  ],\n",
       "       [301.  , 100.  ,   3.  ,   3.5 ,   3.  ,   8.04,   0.  ],\n",
       "       [296.  ,  95.  ,   2.  ,   3.  ,   2.  ,   7.54,   1.  ],\n",
       "       [314.  , 105.  ,   3.  ,   3.5 ,   2.5 ,   8.3 ,   0.  ],\n",
       "       [336.  , 118.  ,   5.  ,   4.5 ,   4.  ,   9.19,   1.  ],\n",
       "       [314.  , 106.  ,   2.  ,   4.  ,   3.5 ,   8.25,   0.  ],\n",
       "       [312.  , 101.  ,   2.  ,   2.5 ,   3.5 ,   8.04,   1.  ],\n",
       "       [323.  , 107.  ,   3.  ,   3.5 ,   3.5 ,   8.55,   1.  ],\n",
       "       [312.  , 107.  ,   4.  ,   4.5 ,   4.  ,   8.65,   1.  ],\n",
       "       [296.  ,  99.  ,   2.  ,   2.5 ,   2.5 ,   8.03,   0.  ],\n",
       "       [325.  , 112.  ,   4.  ,   3.5 ,   3.5 ,   8.92,   0.  ],\n",
       "       [327.  , 112.  ,   3.  ,   3.  ,   3.  ,   8.72,   1.  ],\n",
       "       [318.  , 106.  ,   2.  ,   4.  ,   4.  ,   7.92,   1.  ],\n",
       "       [323.  , 113.  ,   4.  ,   4.  ,   4.5 ,   9.23,   1.  ],\n",
       "       [307.  , 102.  ,   3.  ,   3.  ,   3.  ,   8.27,   0.  ],\n",
       "       [333.  , 117.  ,   4.  ,   5.  ,   4.  ,   9.66,   1.  ],\n",
       "       [322.  , 107.  ,   3.  ,   3.5 ,   3.5 ,   8.46,   1.  ],\n",
       "       [314.  , 107.  ,   2.  ,   2.5 ,   4.  ,   8.27,   0.  ],\n",
       "       [321.  , 109.  ,   3.  ,   3.  ,   4.  ,   8.2 ,   1.  ],\n",
       "       [324.  , 107.  ,   4.  ,   4.  ,   4.5 ,   8.87,   1.  ],\n",
       "       [320.  , 120.  ,   3.  ,   4.  ,   4.5 ,   9.11,   0.  ],\n",
       "       [322.  , 110.  ,   3.  ,   3.  ,   3.5 ,   8.  ,   0.  ],\n",
       "       [315.  , 105.  ,   2.  ,   2.  ,   2.5 ,   7.65,   0.  ],\n",
       "       [307.  , 110.  ,   4.  ,   4.  ,   4.5 ,   8.37,   0.  ],\n",
       "       [306.  , 106.  ,   2.  ,   2.  ,   2.5 ,   8.14,   0.  ],\n",
       "       [304.  , 100.  ,   2.  ,   2.5 ,   3.5 ,   8.07,   0.  ],\n",
       "       [311.  , 104.  ,   2.  ,   2.5 ,   3.5 ,   8.48,   0.  ],\n",
       "       [325.  , 112.  ,   2.  ,   3.  ,   3.5 ,   8.96,   1.  ],\n",
       "       [316.  , 101.  ,   2.  ,   2.5 ,   2.  ,   8.32,   1.  ],\n",
       "       [334.  , 117.  ,   5.  ,   4.  ,   4.5 ,   9.07,   1.  ],\n",
       "       [311.  , 102.  ,   3.  ,   4.5 ,   4.  ,   8.64,   1.  ],\n",
       "       [324.  , 111.  ,   3.  ,   2.5 ,   2.  ,   8.8 ,   1.  ],\n",
       "       [334.  , 116.  ,   4.  ,   4.  ,   3.  ,   8.  ,   1.  ],\n",
       "       [325.  , 106.  ,   3.  ,   3.5 ,   4.  ,   8.4 ,   1.  ],\n",
       "       [322.  , 109.  ,   5.  ,   4.5 ,   3.5 ,   8.8 ,   0.  ],\n",
       "       [322.  , 110.  ,   5.  ,   5.  ,   4.  ,   9.1 ,   1.  ],\n",
       "       [314.  , 106.  ,   3.  ,   3.  ,   5.  ,   8.9 ,   0.  ],\n",
       "       [294.  ,  95.  ,   1.  ,   1.5 ,   1.5 ,   7.64,   0.  ],\n",
       "       [314.  , 103.  ,   2.  ,   2.  ,   3.  ,   8.21,   0.  ],\n",
       "       [297.  ,  98.  ,   2.  ,   2.5 ,   3.  ,   7.67,   0.  ],\n",
       "       [323.  , 110.  ,   5.  ,   4.  ,   5.  ,   8.98,   1.  ],\n",
       "       [324.  , 110.  ,   3.  ,   3.5 ,   3.  ,   9.22,   1.  ],\n",
       "       [320.  , 113.  ,   2.  ,   2.  ,   2.5 ,   8.64,   1.  ],\n",
       "       [330.  , 115.  ,   5.  ,   4.5 ,   3.  ,   9.34,   1.  ],\n",
       "       [326.  , 108.  ,   3.  ,   3.  ,   3.5 ,   8.89,   0.  ],\n",
       "       [320.  , 104.  ,   3.  ,   3.  ,   3.5 ,   8.74,   1.  ],\n",
       "       [308.  , 101.  ,   2.  ,   3.  ,   4.  ,   7.9 ,   0.  ],\n",
       "       [327.  , 108.  ,   5.  ,   5.  ,   3.5 ,   9.13,   1.  ],\n",
       "       [318.  , 109.  ,   3.  ,   3.5 ,   4.  ,   9.22,   1.  ],\n",
       "       [312.  , 107.  ,   3.  ,   3.  ,   2.  ,   7.9 ,   1.  ],\n",
       "       [338.  , 117.  ,   4.  ,   3.5 ,   4.5 ,   9.46,   1.  ],\n",
       "       [311.  , 104.  ,   3.  ,   3.5 ,   2.  ,   8.2 ,   1.  ],\n",
       "       [306.  , 103.  ,   2.  ,   2.5 ,   3.  ,   8.36,   0.  ],\n",
       "       [313.  , 106.  ,   2.  ,   2.5 ,   2.  ,   8.43,   0.  ],\n",
       "       [334.  , 116.  ,   4.  ,   4.  ,   3.5 ,   9.54,   1.  ],\n",
       "       [297.  ,  96.  ,   2.  ,   2.5 ,   1.5 ,   7.89,   0.  ],\n",
       "       [319.  , 110.  ,   3.  ,   3.  ,   2.5 ,   8.79,   0.  ],\n",
       "       [325.  , 111.  ,   3.  ,   3.  ,   3.5 ,   8.7 ,   0.  ],\n",
       "       [320.  , 103.  ,   3.  ,   3.  ,   3.  ,   7.7 ,   0.  ],\n",
       "       [329.  , 111.  ,   4.  ,   4.5 ,   4.5 ,   9.18,   1.  ],\n",
       "       [309.  , 106.  ,   2.  ,   2.5 ,   2.5 ,   8.  ,   0.  ],\n",
       "       [324.  , 111.  ,   4.  ,   3.  ,   3.  ,   9.01,   1.  ],\n",
       "       [310.  , 106.  ,   4.  ,   1.5 ,   2.5 ,   8.36,   0.  ],\n",
       "       [321.  , 109.  ,   3.  ,   3.  ,   3.  ,   8.54,   1.  ],\n",
       "       [324.  , 110.  ,   3.  ,   3.5 ,   3.5 ,   9.04,   1.  ],\n",
       "       [326.  , 116.  ,   3.  ,   3.5 ,   4.  ,   9.14,   1.  ],\n",
       "       [322.  , 104.  ,   3.  ,   3.5 ,   4.  ,   8.84,   1.  ],\n",
       "       [335.  , 115.  ,   4.  ,   4.5 ,   4.5 ,   9.68,   1.  ],\n",
       "       [316.  , 102.  ,   3.  ,   2.  ,   3.  ,   7.4 ,   0.  ],\n",
       "       [302.  , 102.  ,   1.  ,   2.  ,   1.5 ,   8.  ,   0.  ],\n",
       "       [324.  , 111.  ,   5.  ,   4.5 ,   4.  ,   9.16,   1.  ],\n",
       "       [315.  , 105.  ,   3.  ,   2.  ,   2.5 ,   8.48,   0.  ],\n",
       "       [314.  , 109.  ,   4.  ,   3.5 ,   4.  ,   8.77,   1.  ],\n",
       "       [314.  , 102.  ,   2.  ,   2.  ,   2.5 ,   8.24,   0.  ],\n",
       "       [325.  , 110.  ,   2.  ,   3.  ,   2.5 ,   8.76,   1.  ],\n",
       "       [313.  , 102.  ,   3.  ,   3.5 ,   4.  ,   8.9 ,   1.  ]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71, 0.7 , 0.79, 0.73, 0.72, 0.48, 0.77, 0.71, 0.9 , 0.94, 0.58,\n",
       "       0.89, 0.72, 0.57, 0.78, 0.42, 0.64, 0.84, 0.63, 0.72, 0.9 , 0.83,\n",
       "       0.57, 0.47, 0.85, 0.67, 0.44, 0.54, 0.92, 0.62, 0.68, 0.73, 0.73,\n",
       "       0.61, 0.55, 0.74, 0.64, 0.89, 0.73, 0.95, 0.71, 0.72, 0.75, 0.76,\n",
       "       0.86, 0.7 , 0.39, 0.79, 0.61, 0.64, 0.71, 0.8 , 0.61, 0.89, 0.68,\n",
       "       0.79, 0.78, 0.52, 0.76, 0.88, 0.74, 0.49, 0.65, 0.59, 0.87, 0.89,\n",
       "       0.81, 0.9 , 0.8 , 0.76, 0.68, 0.87, 0.68, 0.64, 0.91, 0.61, 0.69,\n",
       "       0.62, 0.93, 0.43, 0.72, 0.52, 0.64, 0.87, 0.62, 0.82, 0.57, 0.79,\n",
       "       0.82, 0.81, 0.78, 0.93, 0.64, 0.5 , 0.9 , 0.75, 0.82, 0.64, 0.75,\n",
       "       0.77])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This step is necessary because both y_test and y_train need to be in the same form.\n",
    "y_test = y_test>0.5\n",
    "y_test = labelencoder.fit_transform(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting the score for decision tree classifier\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "dt_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  6],\n",
       "       [ 1, 91]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP+TN)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy using confusion matrix\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
